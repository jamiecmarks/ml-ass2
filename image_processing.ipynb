{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1461,
   "id": "e476c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "0b53285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"train\"\n",
    "OUTPUT_DIR = \"train_resized\"\n",
    "NUM_IMAGES = 5488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "id": "31d71778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_image_path(image_id):\n",
    "    return os.path.join(INPUT_DIR, f\"img_{image_id:06d}.jpg\")\n",
    "\n",
    "def get_output_image_path(image_id):\n",
    "    return os.path.join(OUTPUT_DIR, f\"img_{image_id:06d}.jpg\")\n",
    "\n",
    "def open_image(image_path):\n",
    "    try:\n",
    "        return Image.open(image_path)\n",
    "    except IOError:\n",
    "        print(f\"Error opening image: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "def save_images(images):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "    for image in images:\n",
    "        # Get the filename from the first image\n",
    "        filename = image.filename\n",
    "        image_id = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "\n",
    "        # Save the modified image\n",
    "        image.save(get_output_image_path(image_id))\n",
    "\n",
    "def save_images_sbs(original, modified):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "    for i, image in enumerate(original):\n",
    "        # Get the filename from the first image\n",
    "        filename = image.filename\n",
    "        image_id = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "\n",
    "        # Put original and modified images side by side\n",
    "        new_image = Image.new('RGB', (modified[i].width * 2, modified[i].height))\n",
    "        new_image.paste(image, (0, 0))\n",
    "        new_image.paste(modified[i], (modified[i].width, 0))\n",
    "\n",
    "        # Save the modified image\n",
    "        new_image.save(get_output_image_path(image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "id": "da597ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Crop images.\n",
    "\"\"\"\n",
    "\n",
    "CROP_MARGINS = (5, 5, 5, 5)  # left, top, right, bottom\n",
    "\n",
    "def crop_images(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        width, height = image.size\n",
    "        left = CROP_MARGINS[0]\n",
    "        top = CROP_MARGINS[1]\n",
    "        right = width - CROP_MARGINS[2]\n",
    "        bottom = height - CROP_MARGINS[3]\n",
    "\n",
    "        # Crop the image\n",
    "        new_image = image.crop((left, top, right, bottom))\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "id": "bd8ebf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert images to grayscale.\n",
    "\"\"\"\n",
    "\n",
    "def convert_grayscale(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Convert the image to grayscale\n",
    "        new_image = image.convert(\"L\")\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "id": "d98f6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Increase contrast\n",
    "\"\"\"\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "def increase_contrast(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Increase the contrast of the image\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        new_image = enhancer.enhance(1.5)  # Increase contrast by 50%\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "id": "457a5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boost exposure if image is too dark\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def get_average_brightness(image):\n",
    "    if image.mode != \"L\":\n",
    "        image = image.convert(\"L\")\n",
    "    image_array = np.array(image)\n",
    "    return image_array.mean()\n",
    "\n",
    "# def boost_exposure(images):\n",
    "#     modified = []\n",
    "\n",
    "#     for image in images:\n",
    "#         # Only boost exposure if the image is too dark\n",
    "#         avg_brightness = get_average_brightness(image)\n",
    "\n",
    "#         if avg_brightness < 100:\n",
    "#             # Increase the brightness of the image\n",
    "#             enhancer = ImageEnhance.Brightness(image)\n",
    "#             new_image = enhancer.enhance(100 / avg_brightness)\n",
    "#             new_image.filename = image.filename\n",
    "#             modified.append(new_image)\n",
    "#         else:\n",
    "#             # If the image is not too dark, keep it as is\n",
    "#             new_image = image.copy()\n",
    "#             new_image.filename = image.filename\n",
    "#             modified.append(new_image)\n",
    "    \n",
    "#     return modified\n",
    "\n",
    "def boost_exposure(images):\n",
    "    # boost brightness if the centeral area is too dark\n",
    "    modified = []\n",
    "    for image in images:\n",
    "        # Only boost exposure if the image is too dark\n",
    "        avg_brightness = get_average_brightness(image)\n",
    "\n",
    "        if avg_brightness < 100:\n",
    "            # Increase the brightness of the image\n",
    "            enhancer = ImageEnhance.Brightness(image)\n",
    "            new_image = enhancer.enhance(100 / avg_brightness)\n",
    "            new_image.filename = image.filename\n",
    "            modified.append(new_image)\n",
    "        else:\n",
    "            # If the image is not too dark, keep it as is\n",
    "            new_image = image.copy()\n",
    "            new_image.filename = image.filename\n",
    "            modified.append(new_image)\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "5812868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Decrease exposure if image is too bright\n",
    "\"\"\"\n",
    "\n",
    "def decrease_exposure(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Only boost exposure if the image is too dark\n",
    "        avg_brightness = get_average_brightness(image)\n",
    "\n",
    "        if avg_brightness > 100:\n",
    "            # Increase the brightness of the image\n",
    "            enhancer = ImageEnhance.Brightness(image)\n",
    "            new_image = enhancer.enhance(100 / avg_brightness)\n",
    "            new_image.filename = image.filename\n",
    "            modified.append(new_image)\n",
    "        else:\n",
    "            # If the image is not too dark, keep it as is\n",
    "            new_image = image.copy()\n",
    "            new_image.filename = image.filename\n",
    "            modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "id": "026df2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Highlight edges in the image using a filter.\n",
    "\"\"\"\n",
    "\n",
    "from PIL import ImageFilter\n",
    "def highlight_edges(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Apply an edge enhancement filter to the image\n",
    "        new_image = image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "id": "d51b6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Increase saturation\n",
    "\"\"\"\n",
    "\n",
    "def increase_saturation(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Increase the saturation of the image\n",
    "        enhancer = ImageEnhance.Color(image)\n",
    "        new_image = enhancer.enhance(1.5)\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "id": "18f2fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import colorsys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.patheffects as path_effects\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "\n",
    "def classify_chunk_context_aware(chunk_rgb, mean_brightness, std_brightness,\n",
    "                                 sat_thresh=0.4, val_thresh=0.3, sigma=1):\n",
    "    chunk = np.array(chunk_rgb) / 255.0\n",
    "    chunk_brightness = np.mean(np.max(chunk, axis=2))\n",
    "\n",
    "    if chunk_brightness < mean_brightness - std_brightness:\n",
    "        return \"black\"\n",
    "    elif chunk_brightness > mean_brightness + std_brightness:\n",
    "        return \"white\"\n",
    "\n",
    "    hue_weights = {\"red\": 0, \"blue\": 0.0, \"yellow\": 0.0}\n",
    "    hue_centres = {\"red\": [0, 360], \"blue\": [230], \"yellow\": [55]}\n",
    "\n",
    "    for row in chunk_rgb:\n",
    "        for r, g, b in row:\n",
    "            h, s, v = colorsys.rgb_to_hsv(r / 255.0, g / 255.0, b / 255.0)\n",
    "            h *= 360\n",
    "\n",
    "            for color, centres in hue_centres.items():\n",
    "                if color == \"yellow\":\n",
    "                    local_sat_thresh = 0.2\n",
    "                    local_val_thresh = 0.2\n",
    "                    local_sigma = sigma * 1.5\n",
    "                elif color == \"red\":\n",
    "                    local_sat_thresh = 0.2\n",
    "                    local_val_thresh = 0.2\n",
    "                    local_sigma = sigma * 1.2\n",
    "                else:\n",
    "                    local_sat_thresh = sat_thresh\n",
    "                    local_val_thresh = val_thresh\n",
    "                    local_sigma = sigma\n",
    "\n",
    "                if s < local_sat_thresh or v < local_val_thresh:\n",
    "                    continue\n",
    "\n",
    "                for centre in centres:\n",
    "                    dist = min(abs(h - centre), 360 - abs(h - centre))\n",
    "                    weight = np.exp(-(dist ** 2) / (2 * local_sigma ** 2)) * s * v\n",
    "                    hue_weights[color] += weight\n",
    "\n",
    "    # hue_weights[\"yellow\"] *= 1.2\n",
    "    # hue_weights[\"red\"] *= 1.1\n",
    "    # hue_weights[\"blue\"] *= 1.1\n",
    "\n",
    "    max_color = max(hue_weights, key=hue_weights.get)\n",
    "    max_weight = hue_weights[max_color]\n",
    "    total_weight = sum(hue_weights.values())\n",
    "\n",
    "    if max_weight == 0 or (total_weight > 0 and max_weight / total_weight < 0.5):\n",
    "        return \"other\"\n",
    "    return max_color\n",
    "\n",
    "def dfs_collect_region(label_grid, start_y, start_x, visited):\n",
    "    rows, cols = len(label_grid), len(label_grid[0])\n",
    "    label = label_grid[start_y][start_x]\n",
    "    stack = [(start_y, start_x)]\n",
    "    visited[start_y][start_x] = True\n",
    "    coords = [(start_y, start_x)]\n",
    "\n",
    "    while stack:\n",
    "        y, x = stack.pop()\n",
    "        for dy, dx in [(-1,0), (1,0), (0,-1), (0,1), (-1,-1), (1,1), (-1,1), (1,-1)]:\n",
    "            ny, nx = y + dy, x + dx\n",
    "            if (0 <= ny < rows and 0 <= nx < cols and\n",
    "                not visited[ny][nx] and label_grid[ny][nx] == label):\n",
    "                visited[ny][nx] = True\n",
    "                stack.append((ny, nx))\n",
    "                coords.append((ny, nx))\n",
    "\n",
    "    size = len(coords)\n",
    "    cy = sum(y for y, _ in coords) / size\n",
    "    cx = sum(x for _, x in coords) / size\n",
    "\n",
    "    return {\n",
    "        \"size\": size,\n",
    "        \"label\": label,\n",
    "        \"cy\": cy,\n",
    "        \"cx\": cx,\n",
    "        \"coords\": coords\n",
    "    }\n",
    "\n",
    "def find_best_sign_colour_region(label_grid, allowed_labels={\"red\", \"blue\", \"yellow\"}, min_touching_size=15):\n",
    "    rows, cols = len(label_grid), len(label_grid[0])\n",
    "    visited = [[False] * cols for _ in range(rows)]\n",
    "    centre_y, centre_x = rows // 2, cols // 2\n",
    "    centre_chunk = (centre_y, centre_x)\n",
    "    regions = []\n",
    "\n",
    "    min_touching_size = 0.2 * (rows * cols)\n",
    "\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            if not visited[y][x] and label_grid[y][x] in allowed_labels:\n",
    "                region = dfs_collect_region(label_grid, y, x, visited)\n",
    "                regions.append(region)\n",
    "\n",
    "    if not regions:\n",
    "        return 0, None, []\n",
    "\n",
    "    # Find all regions that contain the centre\n",
    "    touching = [r for r in regions if centre_chunk in r[\"coords\"] and r[\"size\"] >= min_touching_size]\n",
    "\n",
    "    if touching:\n",
    "        # Choose the largest centre-touching region\n",
    "        best_region = max(touching, key=lambda r: r[\"size\"])\n",
    "    else:\n",
    "        # Fallback: choose largest region overall\n",
    "        best_region = max(regions, key=lambda r: r[\"size\"])\n",
    "\n",
    "    return best_region[\"size\"], best_region[\"label\"], best_region[\"coords\"]\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def mask_inside_convex_hull(image, label_grid):\n",
    "    # Convert image to NumPy array\n",
    "    img_np = np.array(image)\n",
    "\n",
    "    # Get the largest colour group and its coordinates\n",
    "    _, _, coords = find_best_sign_colour_region(label_grid)\n",
    "    if not coords:\n",
    "        return image  # No group found, return original\n",
    "\n",
    "    # Convert coords to proper format for convex hull\n",
    "    points = np.array(coords, dtype=np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "    # Create convex hull from group points\n",
    "    hull = cv2.convexHull(points)\n",
    "\n",
    "    # Create a black mask and draw the convex hull filled\n",
    "    mask = np.zeros((img_np.shape[0], img_np.shape[1]), dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [hull], -1, 255, cv2.FILLED)\n",
    "\n",
    "    # Apply mask to image (preserve 3 channels)\n",
    "    if len(img_np.shape) == 3:\n",
    "        result_np = cv2.bitwise_and(img_np, img_np, mask=mask)\n",
    "    else:\n",
    "        # Grayscale image\n",
    "        result_np = cv2.bitwise_and(img_np, mask)\n",
    "\n",
    "    # Convert back to PIL image\n",
    "    return Image.fromarray(result_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 🖼️ Main overlay plot\n",
    "def plot_chunk_colours_overlay(images, chunk_size=4):\n",
    "    label_map = {\"red\": \"R\", \"blue\": \"B\", \"yellow\": \"Y\", \"black\": \"K\", \"white\": \"W\", \"other\": \"O\"}\n",
    "    colour_map = {\n",
    "        \"red\": (1, 0, 0, 0.4),\n",
    "        \"blue\": (0, 0, 1, 0.4),\n",
    "        \"yellow\": (1, 1, 0, 0.4),\n",
    "        \"black\": (0, 0, 0, 0.4),\n",
    "        \"white\": (1, 1, 1, 0.4),\n",
    "        \"other\": (0.5, 0.5, 0.5, 0.4)\n",
    "    }\n",
    "\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        img_np = np.array(image.convert(\"RGB\"))\n",
    "        height, width, _ = img_np.shape\n",
    "        norm_img = img_np / 255.0\n",
    "        brightness_map = np.max(norm_img, axis=2)\n",
    "        mean_brightness = np.mean(brightness_map)\n",
    "        std_brightness = np.std(brightness_map)\n",
    "\n",
    "        # Classify chunks\n",
    "        label_grid = []\n",
    "        for y in range(0, height, chunk_size):\n",
    "            row = []\n",
    "            for x in range(0, width, chunk_size):\n",
    "                chunk = img_np[y:y+chunk_size, x:x+chunk_size]\n",
    "                label = classify_chunk_context_aware(chunk, mean_brightness, std_brightness)\n",
    "                row.append(label)\n",
    "            label_grid.append(row)\n",
    "\n",
    "        # Use hybrid scoring\n",
    "        size, label, coords = find_best_sign_colour_region(label_grid)\n",
    "        # print(f\"{image.filename}Selected region: {label} with size {size}\")\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.imshow(img_np)\n",
    "        rows, cols = len(label_grid), len(label_grid[0])\n",
    "        coord_set = set(coords)\n",
    "\n",
    "        new_image = mask_inside_convex_hull(image, label_grid)\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                y = i * chunk_size\n",
    "                x = j * chunk_size\n",
    "                label_here = label_grid[i][j]\n",
    "                overlay_colour = colour_map[label_here]\n",
    "                letter = label_map[label_here]\n",
    "\n",
    "                edgecolor = 'cyan' if (i, j) in coord_set else 'white'\n",
    "                linewidth = 1.2 if (i, j) in coord_set else 0.5\n",
    "\n",
    "                rect = patches.Rectangle(\n",
    "                    (x - 0.5, y - 0.5),\n",
    "                    chunk_size,\n",
    "                    chunk_size,\n",
    "                    linewidth=linewidth,\n",
    "                    edgecolor=edgecolor,\n",
    "                    facecolor=overlay_colour\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                ax.text(\n",
    "                    x + chunk_size / 2 - 0.5,\n",
    "                    y + chunk_size / 2 - 0.5,\n",
    "                    letter,\n",
    "                    color='white',\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    fontsize=6,\n",
    "                    fontweight='bold',\n",
    "                    path_effects=[\n",
    "                        path_effects.Stroke(linewidth=1, foreground='black'),\n",
    "                        path_effects.Normal()\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        ax.set_xlim(0, width)\n",
    "        ax.set_ylim(height, 0)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.title(\"Context-Aware Dominant Colour Overlay\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"{image.filename} selected region: {label} with size {size}\")\n",
    "\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "id": "b0efee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_contour_and_mask(images):\n",
    "    modified = []\n",
    "    for image in images:\n",
    "        # Convert Pillow image to OpenCV format\n",
    "        image_np = np.array(image.convert(\"RGB\"))\n",
    "        image_cv = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Convert to grayscale and threshold\n",
    "        gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if not contours:\n",
    "            return None  # No contours found\n",
    "\n",
    "        # Choose the largest contour by area\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Create a blank black mask\n",
    "        mask = np.zeros_like(gray)\n",
    "\n",
    "        # Draw the contour onto the mask in white\n",
    "        cv2.drawContours(mask, [largest_contour], -1, color=255, thickness=-1)\n",
    "\n",
    "        # Convert the mask back to Pillow image\n",
    "        mask_pil = Image.fromarray(mask)\n",
    "        mask_pil.filename = image.filename\n",
    "        modified.append(mask_pil)\n",
    "\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "id": "43ad946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_images(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Resize the image\n",
    "        width, height = image.size\n",
    "        new_size = (width * 2, height * 2)\n",
    "        img_np = np.array(image)\n",
    "        resized = cv2.resize(img_np, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "        new_image = Image.fromarray(resized)\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "id": "37cccb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_images(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Sharpen the image\n",
    "        enhancer = ImageEnhance.Sharpness(image)\n",
    "        new_image = enhancer.enhance(2.0)  # Increase sharpness by 100%\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "id": "7b63b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Convert the image to grayscale\n",
    "        gray_image = image.convert(\"L\")\n",
    "        # Apply a median filter to remove noise\n",
    "        new_image = gray_image.filter(ImageFilter.MedianFilter(size=3))\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "id": "4ea0e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "def get_hog_features(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        gray_image = image.convert(\"L\")\n",
    "        img_np = np.array(gray_image)\n",
    "\n",
    "        # Compute HOG features and visualisation\n",
    "        features, hog_image = hog(img_np, orientations=9, pixels_per_cell=(4, 4),\n",
    "                                  cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
    "\n",
    "        # Enhance contrast for visualisation\n",
    "        hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "        new_image = Image.fromarray((hog_image_rescaled * 255).astype(np.uint8))\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "    \n",
    "    return modified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "id": "f040c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def boost_red_and_desaturate_others(images):\n",
    "    modified = []\n",
    "\n",
    "    for image in images:\n",
    "        # Convert image to RGB → BGR (OpenCV format)\n",
    "        img_rgb = np.array(image.convert(\"RGB\"))\n",
    "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "        img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "\n",
    "        h, s, v = cv2.split(img_hsv)\n",
    "\n",
    "        # Define broader red hue range (OpenCV hue: 0-180)\n",
    "        # Includes dark red to light red, and orangey red\n",
    "        red_mask = (\n",
    "            ((h >= 0) & (h <= 10)) |  # Red to orange-red\n",
    "            ((h >= 165) & (h <= 180))  # Wraparound red\n",
    "        ) & (s > 50) & (v > 30)  # Ensure it’s not too grey or dark\n",
    "\n",
    "        non_red_mask = ~red_mask\n",
    "\n",
    "        # Boost red saturation and brightness\n",
    "        s[red_mask] = np.clip(s[red_mask] * 2.0, 0, 255)\n",
    "        v[red_mask] = np.clip(v[red_mask] * 1.3, 0, 255)\n",
    "\n",
    "        # Desaturate non-reds heavily\n",
    "        s[non_red_mask] *= 0.1\n",
    "\n",
    "        # Recombine and convert back to RGB\n",
    "        img_hsv_mod = cv2.merge([h, s, v]).astype(np.uint8)\n",
    "        img_bgr_mod = cv2.cvtColor(img_hsv_mod, cv2.COLOR_HSV2BGR)\n",
    "        img_rgb_mod = cv2.cvtColor(img_bgr_mod, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        new_image = Image.fromarray(img_rgb_mod)\n",
    "        new_image.filename = image.filename\n",
    "        modified.append(new_image)\n",
    "\n",
    "    return modified\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "id": "1e92dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\n",
    "    resize_images,\n",
    "    crop_images,\n",
    "    boost_exposure,\n",
    "    # boost_red_and_desaturate_others,\n",
    "    # get_contours,\n",
    "    # remove_noise,\n",
    "    # sharpen_images,\n",
    "    highlight_edges,\n",
    "    # get_hog_features,\n",
    "    # decrease_exposure,\n",
    "    # increase_contrast,\n",
    "    # plot_chunk_colours_overlay,\n",
    "    # match_contour_and_mask,\n",
    "    # convert_grayscale,\n",
    "    # increase_saturation,\n",
    "]\n",
    "\n",
    "def apply_filters(images):\n",
    "    for filter_func in filters:\n",
    "        images = filter_func(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "id": "0c3e3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    images = []\n",
    "\n",
    "    # Load images\n",
    "    for i in range(1, NUM_IMAGES + 1):\n",
    "        image = open_image(get_input_image_path(i))\n",
    "        if image:\n",
    "            images.append(image)\n",
    "        # if i % 200 == 0:\n",
    "        #     break\n",
    "\n",
    "    # Apply filters\n",
    "    modified = apply_filters(images)\n",
    "    # save_images(modified)\n",
    "\n",
    "    original_cropped = crop_images(images)\n",
    "    save_images_sbs(original_cropped, modified)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e429c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70095f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24fb52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
