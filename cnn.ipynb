{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_meta = pd.read_csv(\"./train/train_metadata.csv\")\n",
    "train_add_features = pd.read_csv(\"./train/features/additional_features.csv\")\n",
    "train_color_hist = pd.read_csv(\"./train/features/color_histogram.csv\")\n",
    "train_hog_pca = pd.read_csv(\"./train/features/hog_pca.csv\")\n",
    "\n",
    "\n",
    "test_meta = pd.read_csv(\"./test/test_metadata.csv\")\n",
    "# test_meta.drop(\"ClassId\", inplace=True, axis=1) # useless for now\n",
    "test_add_features = pd.read_csv(\"./test/features/additional_features.csv\")\n",
    "test_color_hist = pd.read_csv(\"./test/features/color_histogram.csv\")\n",
    "test_hog_pca = pd.read_csv(\"./test/features/hog_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all the dataframes\n",
    "\n",
    "train_df = pd.merge(train_meta, train_add_features, on = \"image_path\", how = \"left\")\n",
    "train_df = pd.merge(train_df, train_color_hist, on = \"image_path\", how = \"left\")\n",
    "train_df = pd.merge(train_df, train_hog_pca, on = \"image_path\", how = \"left\")\n",
    "\n",
    "test_df = pd.merge(test_meta, test_add_features, on = \"image_path\", how = \"left\")\n",
    "test_df = pd.merge(test_df, test_color_hist, on = \"image_path\", how = \"left\")\n",
    "test_df = pd.merge(test_df, test_hog_pca, on = \"image_path\", how = \"left\")\n",
    "\n",
    "\n",
    "# this is just better for reading files\n",
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(lambda x : \"train/\" + x)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(lambda x : \"test/\" + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"image_path\", \"ClassId\", \"id\"]]\n",
    "\n",
    "test_df = test_df[[\"image_path\", \"ClassId\", \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micha31r/Documents/GitHub/ml-ass2/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1830 - loss: 3.6869\n",
      "Epoch 1: val_accuracy improved from -inf to 0.04736, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 351ms/step - accuracy: 0.1842 - loss: 3.6800 - val_accuracy: 0.0474 - val_loss: 3.9812 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.7575 - loss: 0.9663\n",
      "Epoch 2: val_accuracy improved from 0.04736 to 0.20856, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 356ms/step - accuracy: 0.7577 - loss: 0.9652 - val_accuracy: 0.2086 - val_loss: 3.1661 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.8900 - loss: 0.4718\n",
      "Epoch 3: val_accuracy improved from 0.20856 to 0.72951, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 347ms/step - accuracy: 0.8901 - loss: 0.4714 - val_accuracy: 0.7295 - val_loss: 1.2831 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.9509 - loss: 0.2400\n",
      "Epoch 4: val_accuracy improved from 0.72951 to 0.90073, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 460ms/step - accuracy: 0.9509 - loss: 0.2398 - val_accuracy: 0.9007 - val_loss: 0.4091 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9800 - loss: 0.1220\n",
      "Epoch 5: val_accuracy improved from 0.90073 to 0.96812, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 352ms/step - accuracy: 0.9799 - loss: 0.1220 - val_accuracy: 0.9681 - val_loss: 0.1768 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.9807 - loss: 0.1106\n",
      "Epoch 6: val_accuracy did not improve from 0.96812\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 356ms/step - accuracy: 0.9808 - loss: 0.1105 - val_accuracy: 0.9672 - val_loss: 0.1494 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.9946 - loss: 0.0642\n",
      "Epoch 7: val_accuracy improved from 0.96812 to 0.97177, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 378ms/step - accuracy: 0.9946 - loss: 0.0642 - val_accuracy: 0.9718 - val_loss: 0.1337 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9931 - loss: 0.0591\n",
      "Epoch 8: val_accuracy did not improve from 0.97177\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 351ms/step - accuracy: 0.9931 - loss: 0.0591 - val_accuracy: 0.9709 - val_loss: 0.1250 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.9951 - loss: 0.0389\n",
      "Epoch 9: val_accuracy improved from 0.97177 to 0.97632, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 361ms/step - accuracy: 0.9951 - loss: 0.0389 - val_accuracy: 0.9763 - val_loss: 0.1097 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9986 - loss: 0.0235\n",
      "Epoch 10: val_accuracy did not improve from 0.97632\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 353ms/step - accuracy: 0.9986 - loss: 0.0235 - val_accuracy: 0.9654 - val_loss: 0.1560 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9956 - loss: 0.0300\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.97632\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 348ms/step - accuracy: 0.9956 - loss: 0.0300 - val_accuracy: 0.9736 - val_loss: 0.1089 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9975 - loss: 0.0194\n",
      "Epoch 12: val_accuracy improved from 0.97632 to 0.98179, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 348ms/step - accuracy: 0.9975 - loss: 0.0194 - val_accuracy: 0.9818 - val_loss: 0.0887 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9980 - loss: 0.0172\n",
      "Epoch 13: val_accuracy improved from 0.98179 to 0.98361, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 340ms/step - accuracy: 0.9980 - loss: 0.0172 - val_accuracy: 0.9836 - val_loss: 0.0859 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9998 - loss: 0.0147\n",
      "Epoch 14: val_accuracy improved from 0.98361 to 0.98543, saving model to best_cnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 340ms/step - accuracy: 0.9998 - loss: 0.0146 - val_accuracy: 0.9854 - val_loss: 0.0791 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.9996 - loss: 0.0118\n",
      "Epoch 15: val_accuracy did not improve from 0.98543\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 361ms/step - accuracy: 0.9996 - loss: 0.0118 - val_accuracy: 0.9836 - val_loss: 0.0786 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9995 - loss: 0.0111\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.98543\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 343ms/step - accuracy: 0.9995 - loss: 0.0111 - val_accuracy: 0.9854 - val_loss: 0.0777 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9997 - loss: 0.0094\n",
      "Epoch 17: val_accuracy did not improve from 0.98543\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 340ms/step - accuracy: 0.9996 - loss: 0.0094 - val_accuracy: 0.9854 - val_loss: 0.0780 - learning_rate: 2.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.98543\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9854 - val_loss: 0.0773 - learning_rate: 2.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.9998 - loss: 0.0095\n",
      "Epoch 19: val_accuracy did not improve from 0.98543\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 361ms/step - accuracy: 0.9998 - loss: 0.0095 - val_accuracy: 0.9854 - val_loss: 0.0774 - learning_rate: 4.0000e-06\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9806 - loss: 0.1045\n",
      "Validation accuracy: 0.9854\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step\n"
     ]
    }
   ],
   "source": [
    "# train a CNN to classify the images into classes\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Define image dimensions - smaller for faster training\n",
    "IMG_HEIGHT, IMG_WIDTH = 96, 96\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(image_paths, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            # Convert to grayscale immediately\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = img / 255.0  # Normalize\n",
    "            images.append(img)\n",
    "    \n",
    "    # Reshape to add channel dimension (height, width, 1)\n",
    "    images = [img.reshape(img_height, img_width, 1) for img in images]\n",
    "    return np.array(images)\n",
    "\n",
    "# Get image paths and labels from train_df\n",
    "image_paths = train_df['image_path'].values\n",
    "labels = train_df['ClassId'].values\n",
    "\n",
    "# Load images\n",
    "X_images = load_images(image_paths)\n",
    "\n",
    "# Split data\n",
    "X_train_img, X_val_img, y_train_img, y_val_img = train_test_split(\n",
    "    X_images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Data augmentation with fewer transformations for speed\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Build a custom CNN model for grayscale images\n",
    "def build_cnn_model(num_classes=43):\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        # Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn_model = build_cnn_model()\n",
    "cnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),  # Lower learning rate for better generalization\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Add callbacks\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy instead of loss\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Add model checkpoint to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_cnn_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model with focus on validation metrics\n",
    "history = cnn_model.fit(\n",
    "    X_train_img, y_train_img,\n",
    "    batch_size=32,  # Smaller batch size for better generalization\n",
    "    validation_data=(X_val_img, y_val_img),\n",
    "    epochs=50,  \n",
    "    callbacks=[reduce_lr, early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model saved during training\n",
    "cnn_model = tf.keras.models.load_model('best_cnn_model.h5')\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_acc = cnn_model.evaluate(X_val_img, y_val_img)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "test_image_paths = test_df['image_path'].values\n",
    "X_test_img = load_images(test_image_paths)\n",
    "cnn_predictions = cnn_model.predict(X_test_img)\n",
    "cnn_pred_classes = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Save CNN predictions\n",
    "cnn_pred_df = pd.DataFrame({'id': test_df['id'], 'ClassId': cnn_pred_classes})\n",
    "cnn_pred_df.set_index('id', inplace=True)\n",
    "cnn_pred_df.to_csv('cnn_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
